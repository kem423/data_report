{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='log.log', filemode='a', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e5c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popZeroID(row):\n",
    "    x = row['TitleID'].split(\".\")\n",
    "    return(x[0])\n",
    "\n",
    "\n",
    "def mapTitlebyTitleID(row):\n",
    "    title_id = row['TitleID']\n",
    "    title = mapping.loc[mapping['IDTitle'] == title_id].Title\n",
    "    return(title.to_list()[0])\n",
    "\n",
    "def mapBinding(row):\n",
    "    isbn = row['ISBN']\n",
    "    bind_type = binding_mapping_s22.loc[binding_mapping_s22['BINDING::ISBNBindLineExport'] == isbn]['BINDING::AbbrBind']\n",
    "    return(bind_type.to_list()[0])\n",
    "    \n",
    "def mapPrice(row):\n",
    "    isbn = row['ISBN']\n",
    "    try:\n",
    "        bind_price = binding_mapping_Direct.loc[binding_mapping_Direct['BINDING::ISBNBindLineExport'] == isbn]['BINDING::DomPrice']\n",
    "        return(bind_price.to_list()[0])\n",
    "    except IndexError as ie:\n",
    "        pass\n",
    "    \n",
    "def splitBisac(row):\n",
    "    bisac_1 = row['TITLE::Bisac1']\n",
    "    try:\n",
    "        pieces = bisac_1.split(\"/\")\n",
    "        top_bisac = pieces[0]\n",
    "    except AttributeError as ae:\n",
    "        top_bisac = None\n",
    "    return top_bisac\n",
    "\n",
    "def splitCitations(row):\n",
    "    doi = row['DOI']\n",
    "    first = doi.split(\"/\")\n",
    "    second = first[2].split(\".\")\n",
    "    title_ID = second[0]\n",
    "    return title_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time stamp for file naming\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a1974",
   "metadata": {},
   "source": [
    "Start by pulling in the sales data received from RT DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in All Print and ER sales\n",
    "PRH_TLT_FY19 = pd.read_csv('data_input/{}'.format(input_file_1)\n",
    "\n",
    "PRH_TLT_FY20 = pd.read_excel(open('data_input/{}'.format(input_file_2, 'rb'),\n",
    "              sheet_name='PRH+TLT_FY20') \n",
    "PRH_TLT_FY21 = pd.read_excel(open('data_input/{}'.format(input_file_2, 'rb'),\n",
    "              sheet_name='PRH+TLT_FY21') \n",
    "PRH_TLT_FY22 = pd.read_excel(open('data_input/{}'.format(input_file_2, 'rb'),\n",
    "              sheet_name='PRH+TLT_FY22') \n",
    "PRH_TLT_FY23 = pd.read_excel(open('data_input/{}'.format(input_file_2, 'rb'),\n",
    "              sheet_name='PRH_July-Oct') \n",
    "\n",
    "\n",
    "# Read in All EL sales\n",
    "thirdPartyTransacations_FY20_FY22 = pd.read_excel(open('data_input/{}'.format(input_file_3, 'rb'),\n",
    "              sheet_name='3rdPartyTransacations') \n",
    "thirdPartyTransacations_FY23 = pd.read_excel(open('data_input/{}'.format(input_file_3, 'rb'),\n",
    "              sheet_name='3rdPartyJuly-Oct')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d559337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all EL sales into a single DF\n",
    "all_EL_data = pd.concat([thirdPartyTransacations_FY20_FY22, thirdPartyTransacations_FY23])\n",
    "\n",
    "# Combine all Print and ER sales into a single DF\n",
    "all_sales = [PRH_TLT_FY19, PRH_TLT_FY20, PRH_TLT_FY21, PRH_TLT_FY22, PRH_TLT_FY23]\n",
    "all_PRH_TLT_data = pd.concat(all_sales)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c51e0b",
   "metadata": {},
   "source": [
    "Read and clean EL sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read e-sales in. \n",
    "# Drop empty rows. \n",
    "# Drop and rename columns to match print sales. \n",
    "all_EL_data.dropna(how=\"all\", inplace=True)\n",
    "all_EL_data.rename(columns={'isbn': 'ISBN', 'unitssold': 'Units Sold', 'actualamount': 'Amount Sold', 'date': 'Date' }, inplace=True)\n",
    "all_EL_data['TitleID'] = all_EL_data['TitleID'].astype(str)\n",
    "all_EL_data['ISBN'] = all_EL_data['ISBN'].astype(str)\n",
    "all_EL_data['Date'] = pd.to_datetime(all_EL_data.Date)\n",
    "all_EL_data['Date'] = all_EL_data['Date'].dt.strftime('%m/%Y')\n",
    "\n",
    "all_EL_data = all_EL_data.groupby(['TitleID', 'ISBN', 'Date']).sum()\n",
    "all_EL_data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any empty rows, convert 'TitleID' and 'PRINT isbn' to a string.\n",
    "# Group everything by 'ISBN', 'TitleID', and 'Date (month)'\n",
    "# Rename Print isbn as just 'isbn', which we need to do in order to merge print and electronic sales\n",
    "all_PRH_TLT_data.dropna(how=\"all\", inplace=True)\n",
    "all_PRH_TLT_data.rename(columns={'isbn': 'ISBN', 'unitssold': 'Units Sold', 'actualamount': 'Amount Sold', 'date': 'Date' }, inplace=True)\n",
    "all_PRH_TLT_data['TitleID'] = all_PRH_TLT_data['TitleID'].astype(str)\n",
    "all_PRH_TLT_data['ISBN'] = all_PRH_TLT_data['ISBN'].astype(str)\n",
    "all_PRH_TLT_data['Date'] = pd.to_datetime(all_PRH_TLT_data.Date)\n",
    "all_PRH_TLT_data['Date'] = all_PRH_TLT_data['Date'].dt.strftime('%m/%Y')\n",
    "all_PRH_TLT_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e141f0f",
   "metadata": {},
   "source": [
    "Read and clean print sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide up print and electronic sales\n",
    "# Group everything by 'ISBN', 'TitleID', and 'Date (month)'\n",
    "# Add 'Print' label'\n",
    "print_sales = all_PRH_TLT_data[all_PRH_TLT_data['revenuetype'] != 'Electronic']\n",
    "print_sales = print_sales.groupby(['TitleID', 'ISBN', 'Date']).sum()\n",
    "print_sales.reset_index(inplace=True)\n",
    "print_sales['Format'] = 'Print'\n",
    "\n",
    "er_sales = all_PRH_TLT_data[all_PRH_TLT_data['revenuetype'] == 'Electronic']\n",
    "er_sales = er_sales.groupby(['TitleID', 'ISBN', 'Date']).sum()\n",
    "er_sales.reset_index(inplace=True)\n",
    "er_sales['TitleID'] = er_sales.apply(popZeroID, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb491b",
   "metadata": {},
   "source": [
    "Merge it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19565ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ER and EL sales\n",
    "#  Add 'Format' label\n",
    "e_sales = pd.concat([er_sales, all_EL_data])\n",
    "e_sales['Format'] = 'Electronic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge print and electronic sales\n",
    "merged_sales = pd.concat([print_sales, e_sales])\n",
    "merged_sales = merged_sales [['TitleID', 'ISBN', 'Date', 'Units Sold', 'Amount Sold', 'Format']]\n",
    "merged_sales.to_csv('data_output/merged_sales_{}.csv'.format(dt_string), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312df2f5",
   "metadata": {},
   "source": [
    "Now that we have the data cleaned we need to filter it to only frontlist titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7455327",
   "metadata": {},
   "outputs": [],
   "source": [
    "s22 = pd.read_csv('data_input/{}'.format(season_list_file))\n",
    "s22.dropna(subset=['IDTitle'], inplace=True)\n",
    "s22['IDTitle'] = s22['IDTitle'].astype('str')\n",
    "s22_tid = s22['IDTitle'].to_list()\n",
    "# Filter By S22 and F22 titles only\n",
    "final_df = final_df[final_df['TitleID'].isin(s22_tid)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
